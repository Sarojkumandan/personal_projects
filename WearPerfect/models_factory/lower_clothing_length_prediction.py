# -*- coding: utf-8 -*-
"""Lower_Clothing_Length_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WjCIUuvjk77EUZWcTbjvzZZHKKdvUVZn
"""

# Install (if needed)
# !pip install -q keras-tuner rembg opencv-python

import os
import numpy as np
import pandas as pd
import cv2
import joblib
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils.class_weight import compute_class_weight
from sklearn.metrics import classification_report, confusion_matrix, f1_score, balanced_accuracy_score

import tensorflow as tf
from tensorflow.keras import layers, Model, regularizers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import keras_tuner as kt

# Configuration
IMG_SIZE = (128, 128)
BASE_DIR = "/content/drive/MyDrive/lower_clothing_length_ensemble_tuning"
os.makedirs(BASE_DIR, exist_ok=True)

# Load & preprocess
def load_data():
    df = pd.read_csv("/content/drive/MyDrive/17k_csv/filtered_bottom_wear.csv")
    df["Image_Path"] = "/content/drive/MyDrive/cropped_images_17k/bottom_wear_17k/" + df["Image_ID"]
    df = df[df["lower_clothing_length"].isin(df["lower_clothing_length"].value_counts()[lambda x: x >= 5].index)]
    le = LabelEncoder()
    df["lower_clothing_length"] = le.fit_transform(df["lower_clothing_length"])
    joblib.dump(le, os.path.join(BASE_DIR, "length_encoder.pkl"))
    return df[["Image_Path", "lower_clothing_length"]], le

def preprocess_image(path):
    try:
        img = cv2.imread(path)
        if img is None: return None
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, IMG_SIZE)
        return img / 255.0
    except:
        return None

# Load + Split
data, encoder = load_data()
labels = encoder.classes_
input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3)

train_df, test_df = train_test_split(data, test_size=0.2, stratify=data["lower_clothing_length"], random_state=42)
X_train = np.array([preprocess_image(p) for p in train_df["Image_Path"] if preprocess_image(p) is not None])
y_train = train_df["lower_clothing_length"].iloc[:len(X_train)].values
X_test = np.array([preprocess_image(p) for p in test_df["Image_Path"] if preprocess_image(p) is not None])
y_test = test_df["lower_clothing_length"].iloc[:len(X_test)].values

def build_transfer_model(hp, base_fn, input_shape, num_classes):
    base_model = base_fn(include_top=False, input_shape=input_shape, weights='imagenet')
    unfreeze = hp.Choice('unfreeze_layers', [10, 20, 30])
    for layer in base_model.layers[:-unfreeze]:
        layer.trainable = False
    for layer in base_model.layers[-unfreeze:]:
        layer.trainable = True

    x = layers.GlobalAveragePooling2D()(base_model.output)
    x = layers.BatchNormalization()(x)
    x = layers.Dense(hp.Choice('dense_units', [64, 128, 256]), activation='relu',
                     kernel_regularizer=regularizers.l2(hp.Choice('l2', [1e-3, 5e-4, 1e-4])))(x)
    x = layers.Dropout(hp.Choice('dropout', [0.3, 0.4, 0.5]))(x)
    outputs = layers.Dense(num_classes, activation='softmax')(x)

    return Model(inputs=base_model.input, outputs=outputs)

def model_builder(hp):
    model = build_transfer_model(hp, tf.keras.applications.MobileNetV2, input_shape, len(labels))
    model.compile(
        optimizer=Adam(learning_rate=hp.Choice('lr', [1e-4, 2e-5, 1e-5])),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=['sparse_categorical_accuracy']
    )
    return model

tuner = kt.RandomSearch(
    model_builder,
    objective='val_sparse_categorical_accuracy',
    max_trials=10,
    directory=BASE_DIR,
    project_name='bottomwear_tuning'
)

class_weights = dict(zip(
    np.unique(y_train),
    compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)
))

tuner.search(
    X_train, y_train,
    validation_data=(X_test, y_test),
    epochs=15,
    batch_size=32,
    class_weight=class_weights,
    callbacks=[EarlyStopping(patience=3, restore_best_weights=True)],
    verbose=2
)

best_hps = tuner.get_best_hyperparameters(1)[0]
print("Best Params:", best_hps.values)

base_models = {
    "mobilenet": tf.keras.applications.MobileNetV2,
    "resnet": tf.keras.applications.ResNet50,
    "efficientnet": tf.keras.applications.EfficientNetB0,
    "densenet": tf.keras.applications.DenseNet121
}

models_dict = {
    name: build_transfer_model(best_hps, fn, input_shape, len(labels))
    for name, fn in base_models.items()
}

#  Train and save only best-performing model
history_dict = {}
best_val_loss = float('inf')
best_model_name = None

for name, model in models_dict.items():
    print(f"\n Training {name}")
    model.compile(
        optimizer=Adam(learning_rate=best_hps.get('lr')),
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=["sparse_categorical_accuracy"]
    )

    history = model.fit(
        X_train, y_train,
        validation_data=(X_test, y_test),
        batch_size=32,
        epochs=25,
        class_weight=class_weights,
        callbacks=[EarlyStopping(patience=4, restore_best_weights=True)],
        verbose=1
    )

    val_loss = min(history.history['val_loss'])
    history_dict[name] = history

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        best_model_name = name
        model.save(os.path.join(BASE_DIR, f"best_bottomwear_model.keras"))

print(f"\n Best Model: {best_model_name} (val_loss={best_val_loss:.4f})")

def ensemble_predict(models, X):
    preds = [model.predict(X, verbose=0) for model in models]
    return np.argmax(np.mean(preds, axis=0), axis=1)

def evaluate_model(title, y_true, y_pred, labels, y_train_true=None, y_train_pred=None):
    print(f"\n {title}")
    if y_train_true is not None:
        print("\n Training Evaluation:")
        print(classification_report(y_train_true, y_train_pred, target_names=labels))
        print(f"Macro F1 Score: {f1_score(y_train_true, y_train_pred, average='macro'):.4f}")
        print(f"Balanced Accuracy: {balanced_accuracy_score(y_train_true, y_train_pred):.4f}")

    print("\n Testing Evaluation:")
    print(classification_report(y_true, y_pred, target_names=labels))
    print(f"Macro F1 Score: {f1_score(y_true, y_pred, average='macro'):.4f}")
    print(f"Balanced Accuracy: {balanced_accuracy_score(y_true, y_pred):.4f}")

    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(f'{title} - Confusion Matrix')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.show()

# Evaluate
models_list = list(models_dict.values())
y_pred_test = ensemble_predict(models_list, X_test)
y_pred_train = ensemble_predict(models_list, X_train)

evaluate_model(
    "Ensemble - Bottom Wear (lower_clothing_length)",
    y_test, y_pred_test,
    list(encoder.classes_),
    y_train, y_pred_train
)

